# Ollama Configuration

spring.ai.ollama.base-url=http://localhost:11434
spring.ai.ollama.init.pull-model-strategy=when_missing
spring.ai.ollama.init.timeout=5m
spring.ai.ollama.embedding.enabled=true

spring.ai.ollama.chat.options.model=mistral
spring.ai.ollama.embedding.options.model=nomic-embed-text

# Uncomment this if you want to use Ollama in a Docker container along with PostgreSQL
#spring.docker.compose.file=compose-ollama.yaml